# Algorithmic_Fairness_in_decision-making


With ML/AI systems being wildly deployed and used in every domain it has become increasingly necessary to understand the implicit privacy flaws of ml system and research shows that the inference of training data and testing data's projection are very different in a pictorial space under a given statistical distance.

Future studies have also gone on to show how using a statistical distance and lipschitz function we can achieve fairness subject to our utility function.

The notebook uses fairlearn as library to implement the above.
